import os
import base64
import requests
from typing import TypedDict, Optional

from langgraph.graph import StateGraph
from langchain_community.chat_models.tongyi import ChatTongyi
import os
from dotenv import load_dotenv

load_dotenv(override=True)
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")


# =====================================================
# 1. è¾“å…¥æ•°æ®ï¼ˆä½ çš„ MongoDB å¸–å­ï¼‰
# =====================================================

POST = {
    "post_id": "normalthread_16174804",
    "title": "æ˜¯è°ç»å¸¸å…³é—­è“å±è®°å½•å‘€ï¼Ÿï¼Ÿè¿™éƒ½å¥½å‡ æ¬¡äº†ï¼Œ",
    "content": (
        "CFæ¸¸æˆæ­£çŽ©ç€å°±å¡åœåœ¨æŸä¸ªç”»é¢ï¼Œ\n"
        "èµ„æºç®¡ç†å™¨éƒ½è°ƒä¸å‡ºæ¥ï¼Œé”®ç›˜é¼ æ ‡äº®å±å¹•æ— ä¿¡å·ï¼Œ\n"
        "é‡å¯åŽè“å±è®°å½•æ²¡æ‰“å¼€å¥½å‡ æ¬¡äº†ï¼Œæ˜¯è°å…³çš„ï¼Ÿï¼Ÿè¿™æ˜¯æ€Žä¹ˆå›žäº‹ï¼Ÿï¼Ÿ"
    ),
    "images": [
        "https://p0.ssl.qhmsg.com/t11e3f4274fea347e72ead757dd.jpg"
    ]
}

# =====================================================
# 2. LangGraph State
# =====================================================

class FeedbackState(TypedDict):
    post: dict
    enter_vl: bool
    ai_result: Optional[str]
    status: str

# =====================================================
# 3. å›¾ç‰‡ â†’ base64ï¼ˆçœŸå®ž VL æ‰€éœ€ï¼‰
# =====================================================

def image_url_to_base64(url: str) -> str:
    resp = requests.get(url, timeout=15)
    resp.raise_for_status()
    return base64.b64encode(resp.content).decode("utf-8")

# =====================================================
# 4. å†³ç­–èŠ‚ç‚¹ï¼ˆè¿™é‡Œæ•…æ„ç®€å•ï¼‰
#    ðŸ‘‰ åŽé¢ä½ å¯ä»¥æŽ¥ CLIP / è§„åˆ™ / OCR
# =====================================================

KEYWORDS = ["è“å±", "é»‘å±", "æ— ä¿¡å·", "æ­»æœº", "å¡æ­»"]

def decide_node(state: FeedbackState) -> FeedbackState:
    text = state["post"]["title"] + state["post"]["content"]
    state["enter_vl"] = any(k in text for k in KEYWORDS)
    print(f"[DECIDE] æ˜¯å¦è¿›å…¥ VL: {state['enter_vl']}")
    return state

# =====================================================
# 5. çœŸ Â· Tongyi VL èŠ‚ç‚¹
# =====================================================

def tongyi_vl_node(state: FeedbackState) -> FeedbackState:
    post = state["post"]

    base64_img = image_url_to_base64(post["images"][0])

    messages = [
        {
            "role": "system",
            "content": (
                "ä½ æ˜¯360å®‰å…¨äº§å“çš„AIåˆ†æžåŠ©æ‰‹ï¼Œ"
                "æ“…é•¿åˆ†æžç”¨æˆ·åé¦ˆä¸­çš„ç³»ç»Ÿè“å±ã€é»‘å±ã€æ­»æœºé—®é¢˜ã€‚"
                "è¯·è¾“å‡ºã€é—®é¢˜åˆ¤æ–­ + å¯èƒ½åŽŸå›  + å¤„ç†å»ºè®®ã€‘ã€‚"
            )
        },
        {
            "role": "user",
            "content": [
                {"image": f"data:image/jpeg;base64,{base64_img}"},
                {
                    "text": (
                        f"å¸–å­æ ‡é¢˜ï¼š{post['title']}\n\n"
                        f"å¸–å­å†…å®¹ï¼š{post['content']}\n\n"
                        "è¯·ç»“åˆå›¾ç‰‡ä¸Žæ–‡æœ¬ï¼Œåˆ¤æ–­æ˜¯å¦å±žäºŽç³»ç»Ÿè“å±/æ˜¾ç¤ºå¼‚å¸¸é—®é¢˜ã€‚"
                    )
                }
            ]
        }
    ]

    model = ChatTongyi(model="qwen3-vl-flash")
    resp = model.invoke(messages)

    state["ai_result"] = resp.content
    state["status"] = "done"

    print("[VL] é€šä¹‰ VL å·²è¿”å›žç»“æžœ")
    return state

# =====================================================
# 6. Skip èŠ‚ç‚¹
# =====================================================

def skip_node(state: FeedbackState) -> FeedbackState:
    state["status"] = "skipped"
    return state

# =====================================================
# 7. æ¡ä»¶åˆ†æ”¯
# =====================================================

def route(state: FeedbackState) -> str:
    return "vl" if state["enter_vl"] else "skip"

# =====================================================
# 8. æž„å»º LangGraph
# =====================================================

def build_graph():
    g = StateGraph(FeedbackState)

    g.add_node("decide", decide_node)
    g.add_node("vl", tongyi_vl_node)
    g.add_node("skip", skip_node)

    g.set_entry_point("decide")

    g.add_conditional_edges(
        "decide",
        route,
        {"vl": "vl", "skip": "skip"}
    )

    g.set_finish_point("vl")
    g.set_finish_point("skip")

    return g.compile()

# =====================================================
# 9. ä¸»å‡½æ•°
# =====================================================

if __name__ == "__main__":
    app = build_graph()

    result = app.invoke({
        "post": POST,
        "enter_vl": False,
        "ai_result": None,
        "status": "pending"
    })

    print("\n================= AI æœ€ç»ˆè¾“å‡º =================\n")
    print(result["ai_result"])
